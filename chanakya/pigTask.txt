hdfs dfs -mkdir -p pig 

hdfs dfs -put /home/orienit/pig/employee1.json /user/orienit/pig/employee1.json

A= load '/user/orienit/pig/employee1.json' using JsonLoader('empid:int ,name :chararray,salary:int, dept :chararray');

create 'employee','cf'

store A INTO 'hbase://employee1' using org.apache.pig.backend.hadoop.hbase.HBaseStorage('cf:empid cf:name cf:salary cf:dept');

B =LOAD 'hbase://employee1' using org.apache.pig.backend.hadoop.hbase.HBaseStorage('cf:empid cf:name cf:salary cf:dept', '-loadKey true -limit 5') as 
(empid:int,name:chararray,salary:int,
dept:chararray);



A = LOAD 'kalyan.student_parquet' USING  org.apache.hive.hcatalog.pig.HCatLoader();

create table kalyan.student_parquet1 like kalyan.student_parquet;

STORE A INTO 'kalyan.student_parquet1' USING org.apache.hive.hcatalog.pig.HCatStorer();

----------------------------------------------------
hdfs dfs -mkdir -p pig

hdfs dfs -put /home/orienit/pig/employee1.json /user/orienit/pig/employee1.json

A = LOAD '/user/orienit/pig/employee1.json' using JsonLoader('empid:int, name:chararray, salary:int, dept:chararray');

create 'employee1', 'cf'

STORE A INTO 'hbase://employee1' USING org.apache.pig.backend.hadoop.hbase.HBaseStorage('cf:empid cf:name cf:salary cf:dept');
	   	   
B = LOAD 'hbase://employee1' USING org.apache.pig.backend.hadoop.hbase.HBaseStorage('cf:empid cf:name cf:salary cf:dept', '-loadKey true -limit 5') AS (empid:int, name:chararray, salary:int, dept:chararray);
 
----------------------------------------------------
hdfs dfs -mkdir -p pig

hdfs dfs -put /home/orienit/pig/employee1.xml /user/orienit/pig/employee1.xml

REGISTER /usr/lib/pig/piggybank.jar;

A = load '/user/orienit/pig/employee1.xml' using org.apache.pig.piggybank.storage.XMLLoader('employee') as (employee:chararray);

B = foreach A generate xpath() as empid, xpath() as name, ;

----------------------------------------------------
